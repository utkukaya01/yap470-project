{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e830c3",
   "metadata": {},
   "source": [
    "# **Fake News Detection - Method 2 (Testing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced3602c",
   "metadata": {},
   "source": [
    "Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16a3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7616df",
   "metadata": {},
   "source": [
    "Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d343479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "DATASETS = [\"ISOT\", \"LIAR\"]\n",
    "SAVED_MODELS = Path(\"saved_models/method2\")\n",
    "MAX_LEN = 250\n",
    "PARAMS = [(100, 5),(100, 8),(200, 5),(200, 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f4b25",
   "metadata": {},
   "source": [
    "Function to load method 1 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f07ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def load_aux(ds, df):\n",
    "    obj = joblib.load({\n",
    "        \"ISOT\": \"data/features/ISOT/bow_min30_chi2700.joblib\",\n",
    "        \"LIAR\": \"data/features/LIAR/tfidf_min40_chi2700.joblib\"}[ds])\n",
    "    X = obj[\"vect\"].transform(df)\n",
    "    return obj[\"chi2\"].transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc36791",
   "metadata": {},
   "source": [
    "Calculate model's(Bi-LSTM's) performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2084e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753559221.861059   30507 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753559221.864656   30507 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753559221.873492   30507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753559221.873509   30507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753559221.873511   30507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753559221.873512   30507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "I0000 00:00:1753559226.767694   30507 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1753559228.584715   30620 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on: dataset=ISOT, w2v_dim=100, w2v_window_size=5 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9979    0.9991    0.9985      4696\n",
      "           1     0.9991    0.9977    0.9984      4284\n",
      "\n",
      "    accuracy                         0.9984      8980\n",
      "   macro avg     0.9985    0.9984    0.9984      8980\n",
      "weighted avg     0.9984    0.9984    0.9984      8980\n",
      "\n",
      "Confusion matrix:\n",
      "[[4692    4]\n",
      " [  10 4274]]\n",
      "\n",
      "Results on: dataset=ISOT, w2v_dim=100, w2v_window_size=8 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9979    0.9991    0.9985      4696\n",
      "           1     0.9991    0.9977    0.9984      4284\n",
      "\n",
      "    accuracy                         0.9984      8980\n",
      "   macro avg     0.9985    0.9984    0.9984      8980\n",
      "weighted avg     0.9984    0.9984    0.9984      8980\n",
      "\n",
      "Confusion matrix:\n",
      "[[4692    4]\n",
      " [  10 4274]]\n",
      "\n",
      "Results on: dataset=ISOT, w2v_dim=200, w2v_window_size=5 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9989    0.9987    0.9988      4696\n",
      "           1     0.9986    0.9988    0.9987      4284\n",
      "\n",
      "    accuracy                         0.9988      8980\n",
      "   macro avg     0.9988    0.9988    0.9988      8980\n",
      "weighted avg     0.9988    0.9988    0.9988      8980\n",
      "\n",
      "Confusion matrix:\n",
      "[[4690    6]\n",
      " [   5 4279]]\n",
      "\n",
      "Results on: dataset=ISOT, w2v_dim=200, w2v_window_size=8 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9987    0.9991    0.9989      4696\n",
      "           1     0.9991    0.9986    0.9988      4284\n",
      "\n",
      "    accuracy                         0.9989      8980\n",
      "   macro avg     0.9989    0.9989    0.9989      8980\n",
      "weighted avg     0.9989    0.9989    0.9989      8980\n",
      "\n",
      "Confusion matrix:\n",
      "[[4692    4]\n",
      " [   6 4278]]\n",
      "\n",
      "Results on: dataset=LIAR, w2v_dim=100, w2v_window_size=5 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5962    0.4134    0.4883      1132\n",
      "           1     0.6257    0.7779    0.6935      1427\n",
      "\n",
      "    accuracy                         0.6166      2559\n",
      "   macro avg     0.6109    0.5956    0.5909      2559\n",
      "weighted avg     0.6126    0.6166    0.6027      2559\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 468  664]\n",
      " [ 317 1110]]\n",
      "WARNING:tensorflow:5 out of the last 24 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x798a49f7ab60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x798a49f7ab60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Results on: dataset=LIAR, w2v_dim=100, w2v_window_size=8 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5880    0.4841    0.5310      1132\n",
      "           1     0.6411    0.7309    0.6830      1427\n",
      "\n",
      "    accuracy                         0.6217      2559\n",
      "   macro avg     0.6145    0.6075    0.6070      2559\n",
      "weighted avg     0.6176    0.6217    0.6158      2559\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 548  584]\n",
      " [ 384 1043]]\n",
      "\n",
      "Results on: dataset=LIAR, w2v_dim=200, w2v_window_size=5 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6025    0.4726    0.5297      1132\n",
      "           1     0.6427    0.7526    0.6934      1427\n",
      "\n",
      "    accuracy                         0.6288      2559\n",
      "   macro avg     0.6226    0.6126    0.6115      2559\n",
      "weighted avg     0.6249    0.6288    0.6210      2559\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 535  597]\n",
      " [ 353 1074]]\n",
      "\n",
      "Results on: dataset=LIAR, w2v_dim=200, w2v_window_size=8 model=Bi-LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5934    0.4744    0.5272      1132\n",
      "           1     0.6403    0.7421    0.6874      1427\n",
      "\n",
      "    accuracy                         0.6237      2559\n",
      "   macro avg     0.6168    0.6082    0.6073      2559\n",
      "weighted avg     0.6195    0.6237    0.6166      2559\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 537  595]\n",
      " [ 368 1059]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import models  # type: ignore\n",
    "\n",
    "\n",
    "for ds in DATASETS:\n",
    "    test_df = joblib.load(f\"data/processed/{ds}/{ds.lower()}_test.pkl\")\n",
    "    aux_X = load_aux(ds, test_df[\"cleaned\"].values)\n",
    "    y_true = test_df[\"label\"].values\n",
    "    \n",
    "    tok = joblib.load(SAVED_MODELS / \"tokenizer\" / f\"{ds}.pkl\")\n",
    "    seqs = pad_sequences(tok.texts_to_sequences(test_df[\"cleaned\"]), maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    \n",
    "    for dim, win in PARAMS:\n",
    "        tag = f\"{ds}_{dim}d_win{win}\"\n",
    "        model_path = SAVED_MODELS / \"bilstm\" / f\"{tag}.keras\"\n",
    "        if not model_path.exists():\n",
    "            print(f\"Missing model: {model_path.name}\")\n",
    "            continue\n",
    "        \n",
    "        model = models.load_model(model_path, compile=False)\n",
    "        y_pred_prob = model.predict([seqs, aux_X], batch_size=512, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "        \n",
    "        print(f\"\\nResults on: dataset={ds}, w2v_dim={dim}, w2v_window_size={win} model=Bi-LSTM\")\n",
    "        print(classification_report(y_true, y_pred, digits=4))\n",
    "        \n",
    "        print(\"Confusion matrix:\")\n",
    "        print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
